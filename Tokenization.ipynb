{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"I have three visions for India. \n",
    "In 3000 years of our history people from all over the world have come and invaded us, \n",
    "captured our lands, conquered our minds. From Alexander onwards the Greeks, the Turks, \n",
    "the Moguls, the Portuguese, the British, the French, the Dutch, \n",
    "all of them came and looted us, took over what was ours. \n",
    "Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "We have not grabbed their land, their culture and their history and tried to \n",
    "enforce our way of life on them. Why? Because we respect the freedom of others. \n",
    "That is why my FIRST VISION is that of FREEDOM. \n",
    "I believe that India got its first vision of this in 1857, when we started the war of Independence. \n",
    "It is this freedom that we must protect and nurture and build on. If we are not free, no one will respect us.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'have', 'three', 'visions', 'for', 'India.', 'In', '3000', 'years', 'of', 'our', 'history', 'people', 'from', 'all', 'over', 'the', 'world', 'have', 'come', 'and', 'invaded', 'us,', 'captured', 'our', 'lands,', 'conquered', 'our', 'minds.', 'From', 'Alexander', 'onwards', 'the', 'Greeks,', 'the', 'Turks,', 'the', 'Moguls,', 'the', 'Portuguese,', 'the', 'British,', 'the', 'French,', 'the', 'Dutch,', 'all', 'of', 'them', 'came', 'and', 'looted', 'us,', 'took', 'over', 'what', 'was', 'ours.', 'Yet', 'we', 'have', 'not', 'done', 'this', 'to', 'any', 'other', 'nation.', 'We', 'have', 'not', 'conquered', 'anyone.', 'We', 'have', 'not', 'grabbed', 'their', 'land,', 'their', 'culture', 'and', 'their', 'history', 'and', 'tried', 'to', 'enforce', 'our', 'way', 'of', 'life', 'on', 'them.', 'Why?', 'Because', 'we', 'respect', 'the', 'freedom', 'of', 'others.', 'That', 'is', 'why', 'my', 'FIRST', 'VISION', 'is', 'that', 'of', 'FREEDOM.', 'I', 'believe', 'that', 'India', 'got', 'its', 'first', 'vision', 'of', 'this', 'in', '1857,', 'when', 'we', 'started', 'the', 'war', 'of', 'Independence.', 'It', 'is', 'this', 'freedom', 'that', 'we', 'must', 'protect', 'and', 'nurture', 'and', 'build', 'on.', 'If', 'we', 'are', 'not', 'free,', 'no', 'one', 'will', 'respect', 'us.']\n"
     ]
    }
   ],
   "source": [
    "word_res1 = text.split()\n",
    "print(word_res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I have three visions for India', '\\nIn 3000 years of our history people from all over the world have come and invaded us, \\ncaptured our lands, conquered our minds', 'From Alexander onwards the Greeks, the Turks, \\nthe Moguls, the Portuguese, the British, the French, the Dutch, \\nall of them came and looted us, took over what was ours', '\\nYet we have not done this to any other nation', 'We have not conquered anyone', '\\nWe have not grabbed their land, their culture and their history and tried to \\nenforce our way of life on them', 'Why? Because we respect the freedom of others', '\\nThat is why my FIRST VISION is that of FREEDOM', '\\nI believe that India got its first vision of this in 1857, when we started the war of Independence', '\\nIt is this freedom that we must protect and nurture and build on', 'If we are not free, no one will respect us.']\n"
     ]
    }
   ],
   "source": [
    "sent_res1 = text.split('. ')\n",
    "print(sent_res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'have', 'three', 'visions', 'for', 'India', 'In', '3000', 'years', 'of', 'our', 'history', 'people', 'from', 'all', 'over', 'the', 'world', 'have', 'come', 'and', 'invaded', 'us', 'captured', 'our', 'lands', 'conquered', 'our', 'minds', 'From', 'Alexander', 'onwards', 'the', 'Greeks', 'the', 'Turks', 'the', 'Moguls', 'the', 'Portuguese', 'the', 'British', 'the', 'French', 'the', 'Dutch', 'all', 'of', 'them', 'came', 'and', 'looted', 'us', 'took', 'over', 'what', 'was', 'ours', 'Yet', 'we', 'have', 'not', 'done', 'this', 'to', 'any', 'other', 'nation', 'We', 'have', 'not', 'conquered', 'anyone', 'We', 'have', 'not', 'grabbed', 'their', 'land', 'their', 'culture', 'and', 'their', 'history', 'and', 'tried', 'to', 'enforce', 'our', 'way', 'of', 'life', 'on', 'them', 'Why', 'Because', 'we', 'respect', 'the', 'freedom', 'of', 'others', 'That', 'is', 'why', 'my', 'FIRST', 'VISION', 'is', 'that', 'of', 'FREEDOM', 'I', 'believe', 'that', 'India', 'got', 'its', 'first', 'vision', 'of', 'this', 'in', '1857', 'when', 'we', 'started', 'the', 'war', 'of', 'Independence', 'It', 'is', 'this', 'freedom', 'that', 'we', 'must', 'protect', 'and', 'nurture', 'and', 'build', 'on', 'If', 'we', 'are', 'not', 'free', 'no', 'one', 'will', 'respect', 'us']\n"
     ]
    }
   ],
   "source": [
    "word_res2 = re.findall(\"[\\w']+\", text)\n",
    "print(word_res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I have three visions for India. \\nIn 3000 years of our history people from all over the world have come and invaded us', ' \\ncaptured our lands', ' conquered our minds. From Alexander onwards the Greeks', ' the Turks', ' \\nthe Moguls', ' the Portuguese', ' the British', ' the French', ' the Dutch', ' \\nall of them came and looted us', ' took over what was ours. \\nYet we have not done this to any other nation. We have not conquered anyone. \\nWe have not grabbed their land', ' their culture and their history and tried to \\nenforce our way of life on them. Why', ' Because we respect the freedom of others. \\nThat is why my FIRST VISION is that of FREEDOM. \\nI believe that India got its first vision of this in 1857', ' when we started the war of Independence. \\nIt is this freedom that we must protect and nurture and build on. If we are not free', ' no one will respect us.']\n"
     ]
    }
   ],
   "source": [
    "sent_res2 = re.compile('[,?!]').split(text)\n",
    "print(sent_res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     C:\\Users\\devan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\webtext.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, PunktSentenceTokenizer\n",
    "nltk.download('webtext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'have', 'three', 'visions', 'for', 'India', '.', 'In', '3000', 'years', 'of', 'our', 'history', 'people', 'from', 'all', 'over', 'the', 'world', 'have', 'come', 'and', 'invaded', 'us', ',', 'captured', 'our', 'lands', ',', 'conquered', 'our', 'minds', '.', 'From', 'Alexander', 'onwards', 'the', 'Greeks', ',', 'the', 'Turks', ',', 'the', 'Moguls', ',', 'the', 'Portuguese', ',', 'the', 'British', ',', 'the', 'French', ',', 'the', 'Dutch', ',', 'all', 'of', 'them', 'came', 'and', 'looted', 'us', ',', 'took', 'over', 'what', 'was', 'ours', '.', 'Yet', 'we', 'have', 'not', 'done', 'this', 'to', 'any', 'other', 'nation', '.', 'We', 'have', 'not', 'conquered', 'anyone', '.', 'We', 'have', 'not', 'grabbed', 'their', 'land', ',', 'their', 'culture', 'and', 'their', 'history', 'and', 'tried', 'to', 'enforce', 'our', 'way', 'of', 'life', 'on', 'them', '.', 'Why', '?', 'Because', 'we', 'respect', 'the', 'freedom', 'of', 'others', '.', 'That', 'is', 'why', 'my', 'FIRST', 'VISION', 'is', 'that', 'of', 'FREEDOM', '.', 'I', 'believe', 'that', 'India', 'got', 'its', 'first', 'vision', 'of', 'this', 'in', '1857', ',', 'when', 'we', 'started', 'the', 'war', 'of', 'Independence', '.', 'It', 'is', 'this', 'freedom', 'that', 'we', 'must', 'protect', 'and', 'nurture', 'and', 'build', 'on', '.', 'If', 'we', 'are', 'not', 'free', ',', 'no', 'one', 'will', 'respect', 'us', '.']\n"
     ]
    }
   ],
   "source": [
    "word_res3 = word_tokenize(text)\n",
    "print(word_res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I have three visions for India.', 'In 3000 years of our history people from all over the world have come and invaded us, \\ncaptured our lands, conquered our minds.', 'From Alexander onwards the Greeks, the Turks, \\nthe Moguls, the Portuguese, the British, the French, the Dutch, \\nall of them came and looted us, took over what was ours.', 'Yet we have not done this to any other nation.', 'We have not conquered anyone.', 'We have not grabbed their land, their culture and their history and tried to \\nenforce our way of life on them.', 'Why?', 'Because we respect the freedom of others.', 'That is why my FIRST VISION is that of FREEDOM.', 'I believe that India got its first vision of this in 1857, when we started the war of Independence.', 'It is this freedom that we must protect and nurture and build on.', 'If we are not free, no one will respect us.']\n"
     ]
    }
   ],
   "source": [
    "sent_res3 = sent_tokenize(text)\n",
    "print(sent_res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import webtext\n",
    "train_text = webtext.raw('overheard.txt')\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "tokenized = custom_sent_tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I have three visions for India.', 'In 3000 years of our history people from all over the world have come and invaded us, \\ncaptured our lands, conquered our minds.', 'From Alexander onwards the Greeks, the Turks, \\nthe Moguls, the Portuguese, the British, the French, the Dutch, \\nall of them came and looted us, took over what was ours.', 'Yet we have not done this to any other nation.', 'We have not conquered anyone.', 'We have not grabbed their land, their culture and their history and tried to \\nenforce our way of life on them.', 'Why?', 'Because we respect the freedom of others.', 'That is why my FIRST VISION is that of FREEDOM.', 'I believe that India got its first vision of this in 1857, when we started the war of Independence.', 'It is this freedom that we must protect and nurture and build on.', 'If we are not free, no one will respect us.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'have', 'three', 'visions', 'for', 'India', '.', '\\n', 'In', '3000', 'years', 'of', 'our', 'history', 'people', 'from', 'all', 'over', 'the', 'world', 'have', 'come', 'and', 'invaded', 'us', ',', '\\n', 'captured', 'our', 'lands', ',', 'conquered', 'our', 'minds', '.', 'From', 'Alexander', 'onwards', 'the', 'Greeks', ',', 'the', 'Turks', ',', '\\n', 'the', 'Moguls', ',', 'the', 'Portuguese', ',', 'the', 'British', ',', 'the', 'French', ',', 'the', 'Dutch', ',', '\\n', 'all', 'of', 'them', 'came', 'and', 'looted', 'us', ',', 'took', 'over', 'what', 'was', 'ours', '.', '\\n', 'Yet', 'we', 'have', 'not', 'done', 'this', 'to', 'any', 'other', 'nation', '.', 'We', 'have', 'not', 'conquered', 'anyone', '.', '\\n', 'We', 'have', 'not', 'grabbed', 'their', 'land', ',', 'their', 'culture', 'and', 'their', 'history', 'and', 'tried', 'to', '\\n', 'enforce', 'our', 'way', 'of', 'life', 'on', 'them', '.', 'Why', '?', 'Because', 'we', 'respect', 'the', 'freedom', 'of', 'others', '.', '\\n', 'That', 'is', 'why', 'my', 'FIRST', 'VISION', 'is', 'that', 'of', 'FREEDOM', '.', '\\n', 'I', 'believe', 'that', 'India', 'got', 'its', 'first', 'vision', 'of', 'this', 'in', '1857', ',', 'when', 'we', 'started', 'the', 'war', 'of', 'Independence', '.', '\\n', 'It', 'is', 'this', 'freedom', 'that', 'we', 'must', 'protect', 'and', 'nurture', 'and', 'build', 'on', '.', 'If', 'we', 'are', 'not', 'free', ',', 'no', 'one', 'will', 'respect', 'us', '.']\n"
     ]
    }
   ],
   "source": [
    "my_doc = nlp(text)\n",
    "word_list = []\n",
    "for token in my_doc:\n",
    "    word_list.append(token.text)\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.sentencizer.Sentencizer object at 0x000001B673616908> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-8d8a63cb7f55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msbd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sentencizer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msbd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msent_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    746\u001b[0m             \u001b[0mbad_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactory_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE966\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbad_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfactory_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.sentencizer.Sentencizer object at 0x000001B673616908> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "sbd = nlp.create_pipe('sentencizer')\n",
    "nlp.add_pipe(sbd)\n",
    "doc = nlp(text)\n",
    "sent_list = []\n",
    "for sent in doc.sents:\n",
    "    sent_list.append(sent.text)\n",
    "print(sent_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'have',\n",
       " 'three',\n",
       " 'visions',\n",
       " 'for',\n",
       " 'india',\n",
       " 'in',\n",
       " '3000',\n",
       " 'years',\n",
       " 'of',\n",
       " 'our',\n",
       " 'history',\n",
       " 'people',\n",
       " 'from',\n",
       " 'all',\n",
       " 'over',\n",
       " 'the',\n",
       " 'world',\n",
       " 'have',\n",
       " 'come',\n",
       " 'and',\n",
       " 'invaded',\n",
       " 'us',\n",
       " 'captured',\n",
       " 'our',\n",
       " 'lands',\n",
       " 'conquered',\n",
       " 'our',\n",
       " 'minds',\n",
       " 'from',\n",
       " 'alexander',\n",
       " 'onwards',\n",
       " 'the',\n",
       " 'greeks',\n",
       " 'the',\n",
       " 'turks',\n",
       " 'the',\n",
       " 'moguls',\n",
       " 'the',\n",
       " 'portuguese',\n",
       " 'the',\n",
       " 'british',\n",
       " 'the',\n",
       " 'french',\n",
       " 'the',\n",
       " 'dutch',\n",
       " 'all',\n",
       " 'of',\n",
       " 'them',\n",
       " 'came',\n",
       " 'and',\n",
       " 'looted',\n",
       " 'us',\n",
       " 'took',\n",
       " 'over',\n",
       " 'what',\n",
       " 'was',\n",
       " 'ours',\n",
       " 'yet',\n",
       " 'we',\n",
       " 'have',\n",
       " 'not',\n",
       " 'done',\n",
       " 'this',\n",
       " 'to',\n",
       " 'any',\n",
       " 'other',\n",
       " 'nation',\n",
       " 'we',\n",
       " 'have',\n",
       " 'not',\n",
       " 'conquered',\n",
       " 'anyone',\n",
       " 'we',\n",
       " 'have',\n",
       " 'not',\n",
       " 'grabbed',\n",
       " 'their',\n",
       " 'land',\n",
       " 'their',\n",
       " 'culture',\n",
       " 'and',\n",
       " 'their',\n",
       " 'history',\n",
       " 'and',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'enforce',\n",
       " 'our',\n",
       " 'way',\n",
       " 'of',\n",
       " 'life',\n",
       " 'on',\n",
       " 'them',\n",
       " 'why',\n",
       " 'because',\n",
       " 'we',\n",
       " 'respect',\n",
       " 'the',\n",
       " 'freedom',\n",
       " 'of',\n",
       " 'others',\n",
       " 'that',\n",
       " 'is',\n",
       " 'why',\n",
       " 'my',\n",
       " 'first',\n",
       " 'vision',\n",
       " 'is',\n",
       " 'that',\n",
       " 'of',\n",
       " 'freedom',\n",
       " 'i',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'india',\n",
       " 'got',\n",
       " 'its',\n",
       " 'first',\n",
       " 'vision',\n",
       " 'of',\n",
       " 'this',\n",
       " 'in',\n",
       " '1857',\n",
       " 'when',\n",
       " 'we',\n",
       " 'started',\n",
       " 'the',\n",
       " 'war',\n",
       " 'of',\n",
       " 'independence',\n",
       " 'it',\n",
       " 'is',\n",
       " 'this',\n",
       " 'freedom',\n",
       " 'that',\n",
       " 'we',\n",
       " 'must',\n",
       " 'protect',\n",
       " 'and',\n",
       " 'nurture',\n",
       " 'and',\n",
       " 'build',\n",
       " 'on',\n",
       " 'if',\n",
       " 'we',\n",
       " 'are',\n",
       " 'not',\n",
       " 'free',\n",
       " 'no',\n",
       " 'one',\n",
       " 'will',\n",
       " 'respect',\n",
       " 'us']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = text_to_word_sequence(text)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization.textcleaner import split_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I have three visions for India.', 'In 3000 years of our history people from all over the world have come and invaded us, ', 'captured our lands, conquered our minds.', 'From Alexander onwards the Greeks, the Turks, ', 'the Moguls, the Portuguese, the British, the French, the Dutch, ', 'all of them came and looted us, took over what was ours.', 'Yet we have not done this to any other nation.', 'We have not conquered anyone.', 'We have not grabbed their land, their culture and their history and tried to ', 'enforce our way of life on them.', 'Why?', 'Because we respect the freedom of others.', 'That is why my FIRST VISION is that of FREEDOM.', 'I believe that India got its first vision of this in 1857, when we started the war of Independence.', 'It is this freedom that we must protect and nurture and build on.', 'If we are not free, no one will respect us.']\n"
     ]
    }
   ],
   "source": [
    "sent_res4 = split_sentences(text)\n",
    "print(sent_res4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'have', 'three', 'visions', 'for', 'India', 'In', 'years', 'of', 'our', 'history', 'people', 'from', 'all', 'over', 'the', 'world', 'have', 'come', 'and', 'invaded', 'us', 'captured', 'our', 'lands', 'conquered', 'our', 'minds', 'From', 'Alexander', 'onwards', 'the', 'Greeks', 'the', 'Turks', 'the', 'Moguls', 'the', 'Portuguese', 'the', 'British', 'the', 'French', 'the', 'Dutch', 'all', 'of', 'them', 'came', 'and', 'looted', 'us', 'took', 'over', 'what', 'was', 'ours', 'Yet', 'we', 'have', 'not', 'done', 'this', 'to', 'any', 'other', 'nation', 'We', 'have', 'not', 'conquered', 'anyone', 'We', 'have', 'not', 'grabbed', 'their', 'land', 'their', 'culture', 'and', 'their', 'history', 'and', 'tried', 'to', 'enforce', 'our', 'way', 'of', 'life', 'on', 'them', 'Why', 'Because', 'we', 'respect', 'the', 'freedom', 'of', 'others', 'That', 'is', 'why', 'my', 'FIRST', 'VISION', 'is', 'that', 'of', 'FREEDOM', 'I', 'believe', 'that', 'India', 'got', 'its', 'first', 'vision', 'of', 'this', 'in', 'when', 'we', 'started', 'the', 'war', 'of', 'Independence', 'It', 'is', 'this', 'freedom', 'that', 'we', 'must', 'protect', 'and', 'nurture', 'and', 'build', 'on', 'If', 'we', 'are', 'not', 'free', 'no', 'one', 'will', 'respect', 'us']\n"
     ]
    }
   ],
   "source": [
    "word_res4 = list(tokenize(text))\n",
    "print(word_res4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
